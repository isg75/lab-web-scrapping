{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rq7Fx0T_DPsE"
   },
   "source": [
    "# Web Scrapping lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3n7CJfCD2pK"
   },
   "source": [
    "In this lab you will scrappe this [website](https://books.toscrape.com/) of books.\n",
    "\n",
    "You have to create a Pandas DataFrame with all the books listed in the page. Each row of the DataFrame should contain information of each book. In particular, the DataFrmae must contain:\n",
    "\n",
    "* category\n",
    "* title\n",
    "* price\n",
    "* stock availability\n",
    "* star rating (number of stars)\n",
    "* description\n",
    "* UPC\n",
    "\n",
    "Happy scrapping!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaqLnJRLBqMS"
   },
   "source": [
    "# Server verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNXuRli_BvJp"
   },
   "source": [
    "Load the needed libraries, and make sure thar you can obtain the correct status code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szKOZm99Frlf",
    "outputId": "184b2f54-7eaa-4d31-b66f-f3f8311e80e6"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Set up the URL for scraping\n",
    "base_url = 'http://books.toscrape.com/catalogue/page-{}.html'  # Pagination URL\n",
    "books_data = []\n",
    "\n",
    "# Loop through multiple pages\n",
    "for page in range(1, 3):  # Change range for more pages\n",
    "    url = base_url.format(page)\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check the status code\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Successfully accessed page {page}.\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page {page}. Status code: {response.status_code}\")\n",
    "        continue  # Skip to the next iteration\n",
    "\n",
    "    # Step 3: Parse the HTML\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Step 4: Extract the required information\n",
    "    for book in soup.select('.product_pod'):\n",
    "        title = book.h3.a['title']  # Title of the book\n",
    "        price = book.select_one('.price_color').get_text(strip=True)  # Price\n",
    "        stock_availability = book.select_one('.instock.availability').get_text(strip=True)  # Stock\n",
    "        star_rating = book.select_one('.star-rating')['class'][1]  # Extract star rating class\n",
    "\n",
    "        # Extract the link to the book details page to get UPC and description\n",
    "        book_link = book.h3.a['href']\n",
    "        book_detail_url = f\"http://books.toscrape.com/catalogue/{book_link}\"\n",
    "        detail_response = requests.get(book_detail_url)\n",
    "        \n",
    "        if detail_response.status_code == 200:\n",
    "            detail_soup = BeautifulSoup(detail_response.content, 'html.parser')\n",
    "            description = detail_soup.select_one('#product_description + p').get_text(strip=True)  # Description\n",
    "            UPC = detail_soup.select_one('table tr:nth-of-type(1) td').get_text(strip=True)  # UPC\n",
    "        else:\n",
    "            print(f\"Failed to retrieve details for {title}. Status code: {detail_response.status_code}\")\n",
    "            description = None\n",
    "            UPC = None\n",
    "\n",
    "        # Convert star rating class to numeric rating\n",
    "        star_mapping = {\n",
    "            'One': 1,\n",
    "            'Two': 2,\n",
    "            'Three': 3,\n",
    "            'Four': 4,\n",
    "            'Five': 5\n",
    "        }\n",
    "        star_rating_numeric = star_mapping.get(star_rating, 0)\n",
    "\n",
    "        # Append book data to the list\n",
    "        books_data.append({\n",
    "            'title': title,\n",
    "            'price': price,\n",
    "            'stock availability': stock_availability,\n",
    "            'star rating': star_rating_numeric,\n",
    "            'description': description,\n",
    "            'UPC': UPC\n",
    "        })\n",
    "\n",
    "# Step 5: Create a Pandas DataFrame\n",
    "books_df = pd.DataFrame(books_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(books_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSrTPTKnCD-N"
   },
   "source": [
    "# Book categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yu5FjaMECISF"
   },
   "source": [
    "Create the code to collect the **relative urls** from the left panel to obtain a list with all the book categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y12krHNrGPsu",
    "outputId": "8e1a4907-1b82-4f2d-f8a9-c7c10b6e6bed"
   },
   "outputs": [],
   "source": [
    "#Step 1: Set up the URL for scraping the main page\n",
    "url = 'http://books.toscrape.com/'\n",
    "\n",
    "# Step 2: Make a request to the main page\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check the status code\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully accessed the main page.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the main page. Status code: {response.status_code}\")\n",
    "\n",
    "# Step 3: Parse the HTML\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Step 4: Extract category links from the left panel\n",
    "categories = soup.select('.side_categories ul li a')  # Select the category links\n",
    "\n",
    "# Step 5: Collect relative URLs and category names\n",
    "category_list = []\n",
    "for category in categories:\n",
    "    category_name = category.get_text(strip=True)\n",
    "    category_url = category['href']  # Relative URL\n",
    "    category_list.append({\n",
    "        'name': category_name,\n",
    "        'url': category_url\n",
    "    })\n",
    "\n",
    "# Step 6: Display the collected categories\n",
    "for cat in category_list:\n",
    "    print(f\"Category: {cat['name']}, URL: {cat['url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAq9izU8Cpyx"
   },
   "source": [
    "# Books in a given category\n",
    "\n",
    "Use. web scrapping and list comprehension to obtain the **absolute** url of each book to be scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gC6uP76bHwNv"
   },
   "outputs": [],
   "source": [
    "# Step 1: Set up the base URL for scraping the main page\n",
    "base_url = 'http://books.toscrape.com/'\n",
    "url = base_url  # Main page URL\n",
    "\n",
    "# Step 2: Make a request to the main page\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check the status code\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully accessed the main page.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the main page. Status code: {response.status_code}\")\n",
    "\n",
    "# Step 3: Parse the HTML\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Step 4: Extract relative URLs of books and convert to absolute URLs using list comprehension\n",
    "book_links = [base_url + book.h3.a['href'] for book in soup.select('.product_pod')]\n",
    "\n",
    "# Step 5: Display the absolute URLs of the books\n",
    "for link in book_links:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLIh0a_LDJMo"
   },
   "source": [
    "# Book details\n",
    "\n",
    "Create a Python function that given a book_url as an input returns a dictionary with the following structure:\n",
    "\n",
    "```Python\n",
    "{\"Title\": title, \"Price\": price, \"Availability\": availability, \"Rating\": rating, \"Description\": description, \"UPC\": upc}\n",
    "```\n",
    "\n",
    "where `description` should contain the book's summary given in the Product description, and the values are the book's associated information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-uC7hz1LxCd"
   },
   "outputs": [],
   "source": [
    "def get_book_info(book_url):\n",
    "    # Step 1: Make a request to the book's URL\n",
    "    response = requests.get(book_url)\n",
    "\n",
    "    # Check the status code\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the book page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    # Step 2: Parse the HTML content of the book page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Step 3: Extract the required information\n",
    "    title = soup.h1.get_text(strip=True)  # Title\n",
    "    price = soup.select_one('.price_color').get_text(strip=True)  # Price\n",
    "    availability = soup.select_one('.instock.availability').get_text(strip=True)  # Availability\n",
    "    rating = soup.select_one('.star-rating')['class'][1]  # Extract star rating class\n",
    "    \n",
    "    # Convert star rating class to numeric rating\n",
    "    star_mapping = {\n",
    "        'One': 1,\n",
    "        'Two': 2,\n",
    "        'Three': 3,\n",
    "        'Four': 4,\n",
    "        'Five': 5\n",
    "    }\n",
    "    rating_numeric = star_mapping.get(rating, 0)\n",
    "\n",
    "    # Description (summary) and UPC extraction\n",
    "    description = soup.select_one('#product_description + p').get_text(strip=True)  # Description\n",
    "    upc = soup.select_one('table tr:nth-of-type(1) td').get_text(strip=True)  # UPC\n",
    "\n",
    "    # Step 4: Return the extracted information in a dictionary\n",
    "    return {\n",
    "        \"Title\": title,\n",
    "        \"Price\": price,\n",
    "        \"Availability\": availability,\n",
    "        \"Rating\": rating_numeric,\n",
    "        \"Description\": description,\n",
    "        \"UPC\": upc\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "book_url = 'http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'  # Replace with a valid book URL\n",
    "book_info = get_book_info(book_url)\n",
    "print(book_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvSqhX4UDxbb"
   },
   "source": [
    "# Collect and store all the information from the books in a Pandas DataFrame\n",
    "\n",
    "Start with the following dictionary:\n",
    "\n",
    "```python\n",
    "books_dict = {\"Title\": [], \"Price\": [], \"Availability\": [], \"Rating\": [], \"Description\": [], \"UPC\": [], \"Category\": [] }\n",
    "```\n",
    "\n",
    "Then, iterate over all the categories and all the books in a given category to collect any book information using the previous function. Fill the previous dictionary with the information about each book.\n",
    "\n",
    "Show the first five rows of the previous final Pandas DataFrame.\n",
    "\n",
    "Tip: You can use the function `tqdm` from the library `tqdm` to show a progress bar if in iterable of a for loop as shown below :wink: :\n",
    "\n",
    "```python\n",
    "from tqdm import tqdm\n",
    "\n",
    "for elem in tqdm(iterable):\n",
    "    # some code\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "apeImoCxStA5",
    "outputId": "20d2d37c-5cbe-4062-e407-80f77955a8d3"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_book_info(book_url):\n",
    "    \"\"\"Fetch book details from the book page.\"\"\"\n",
    "    response = requests.get(book_url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the book page. Status code: {response.status_code} for URL: {book_url}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    title = soup.h1.get_text(strip=True)  # Title\n",
    "    price = soup.select_one('.price_color').get_text(strip=True)  # Price\n",
    "    availability = soup.select_one('.instock.availability').get_text(strip=True)  # Availability\n",
    "    rating = soup.select_one('.star-rating')['class'][1]  # Rating\n",
    "    star_mapping = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}\n",
    "    rating_numeric = star_mapping.get(rating, 0)\n",
    "    description = soup.select_one('#product_description + p').get_text(strip=True)  # Description\n",
    "    upc = soup.select_one('table tr:nth-of-type(1) td').get_text(strip=True)  # UPC\n",
    "\n",
    "    return {\n",
    "        \"Title\": title,\n",
    "        \"Price\": price,\n",
    "        \"Availability\": availability,\n",
    "        \"Rating\": rating_numeric,\n",
    "        \"Description\": description,\n",
    "        \"UPC\": upc\n",
    "    }\n",
    "\n",
    "# Step 1: Collect all category URLs\n",
    "base_url = 'http://books.toscrape.com/'\n",
    "response = requests.get(base_url)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print(f\"Failed to retrieve the main page. Status code: {response.status_code}\")\n",
    "else:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract category links from the left panel\n",
    "    categories = soup.select('.side_categories ul li a')\n",
    "    category_links = {cat.get_text(strip=True): base_url + cat['href'] for cat in categories if cat['href'] != '#'}\n",
    "\n",
    "    # Step 2: Initialize books_dict\n",
    "    books_dict = {\n",
    "        \"Title\": [],\n",
    "        \"Price\": [],\n",
    "        \"Availability\": [],\n",
    "        \"Rating\": [],\n",
    "        \"Description\": [],\n",
    "        \"UPC\": [],\n",
    "        \"Category\": []\n",
    "    }\n",
    "\n",
    "    # Step 3: Iterate over each category and collect book information\n",
    "    for category_name, category_url in tqdm(category_links.items(), desc=\"Processing categories\"):\n",
    "        while category_url:  # Loop to handle pagination\n",
    "            category_response = requests.get(category_url)\n",
    "            if category_response.status_code != 200:\n",
    "                print(f\"Failed to retrieve the category page. Status code: {category_response.status_code} for URL: {category_url}\")\n",
    "                break\n",
    "\n",
    "            category_soup = BeautifulSoup(category_response.content, 'html.parser')\n",
    "\n",
    "            # Find all book links on the category page\n",
    "            book_links = [base_url + book.h3.a['href'] for book in category_soup.select('.product_pod')]\n",
    "\n",
    "            if not book_links:\n",
    "                print(f\"No books found in category: {category_name}\")\n",
    "                break\n",
    "\n",
    "            # Use tqdm to show a progress bar for book processing\n",
    "            for book_link in tqdm(book_links, desc=f\"Processing books in {category_name}\", leave=False):\n",
    "                book_info = get_book_info(book_link)\n",
    "                if book_info:\n",
    "                    # Fill the dictionary with book information\n",
    "                    books_dict[\"Title\"].append(book_info[\"Title\"])\n",
    "                    books_dict[\"Price\"].append(book_info[\"Price\"])\n",
    "                    books_dict[\"Availability\"].append(book_info[\"Availability\"])\n",
    "                    books_dict[\"Rating\"].append(book_info[\"Rating\"])\n",
    "                    books_dict[\"Description\"].append(book_info[\"Description\"])\n",
    "                    books_dict[\"UPC\"].append(book_info[\"UPC\"])\n",
    "                    books_dict[\"Category\"].append(category_name)\n",
    "\n",
    "            # Check for the next page\n",
    "            next_page = category_soup.select_one('.next a')\n",
    "            if next_page:\n",
    "                category_url = base_url + next_page['href']  # Update the URL to the next page\n",
    "            else:\n",
    "                break  # No more pages\n",
    "\n",
    "    # Step 4: Create a Pandas DataFrame from the dictionary\n",
    "    books_df = pd.DataFrame(books_dict)\n",
    "\n",
    "    # Step 5: Display the first five rows of the DataFrame\n",
    "    print(books_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

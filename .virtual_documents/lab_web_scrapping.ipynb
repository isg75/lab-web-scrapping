











import requests
from bs4 import BeautifulSoup
import pandas as pd

url = "https://books.toscrape.com"
response = requests.get(url)

if response.status_code == 200:
    print ("All good!")
else:
    print(f"Failed to connect. Status code:{response.status_code}")








soup = BeautifulSoup(response.content, "html.parser")

categories_list = []

categories = soup.find('ul', class_='nav-list').find('ul').find_all('li')

for category in categories:
    category_url = category.a['href'] 
    categories_list.append(category_url)

categories_list





base_url = "http://books.toscrape.com/catalogue/"

book_urls = [base_url + book.h3.a['href'].replace('../../../', '') for book in soup.find_all('article', class_='product_pod')]
book_urls





import requests
from bs4 import BeautifulSoup

def scrape_book_details(book_url):

    response = requests.get(book_url)
    if response.status_code != 200:
        return {"error": "Failed to retrieve the book page."}
    
    soup = BeautifulSoup(response.content, "html.parser")
    
    title = soup.find('h1').text
    
    price = soup.find('p', class_='price_color').text
    
    availability = soup.find('p', class_='instock availability').text.strip()
    
    rating = soup.find('p', class_='star-rating')['class'][1]
    rating_dict = {'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5}
    rating = rating_dict.get(rating, "Unknown")
    
    description_tag = soup.find('meta', {'name': 'description'})
    description = description_tag['content'].strip() if description_tag else "No description available"

    upc = soup.find('th', string='UPC').find_next_sibling('td').text
    
    category = soup.find('ul', class_='breadcrumb').find_all('li')[2].text.strip()
    
    return {
        "Title": title,
        "Price": price,
        "Availability": availability,
        "Rating": rating,
        "Description": description,
        "UPC": upc,
        "Category": category
    }

book_url = "http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html"
book_details = scrape_book_details(book_url)
book_details





from tqdm import tqdm

books_dict = {"Title": [], "Price": [], "Availability": [], "Rating": [], "Description": [], "UPC": [], "Category": []}

base_url = "http://books.toscrape.com/"
response = requests.get(base_url)
soup = BeautifulSoup(response.content, "html.parser")

categories = soup.find('ul', class_='nav-list').find('ul').find_all('li')
category_urls = [base_url + category.a['href'] for category in categories]

for category_url in tqdm(category_urls):
    response = requests.get(category_url)
    soup = BeautifulSoup(response.content, "html.parser")
    
    book_urls = [base_url + "catalogue/" + book.h3.a['href'].replace('../../../', '') for book in soup.find_all('article', class_='product_pod')]
    
    for book_url in book_urls:
        book_details = scrape_book_details(book_url)
        books_dict["Title"].append(book_details["Title"])
        books_dict["Price"].append(book_details["Price"])
        books_dict["Availability"].append(book_details["Availability"])
        books_dict["Rating"].append(book_details["Rating"])
        books_dict["Description"].append(book_details["Description"])
        books_dict["UPC"].append(book_details["UPC"])
        books_dict["Category"].append(book_details["Category"])

books_df = pd.DataFrame(books_dict)
books_df


books_df.head()



